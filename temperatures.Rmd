---
title: "Final project - Temperatures"
author: "Nikola Grlj"
date: "2/4/2022"
output: html_document
---
# Spatio-temporal interpolation of mean temperature values for Croatia in period 2004-2020

### Summary
1. [**Introduction**](#chapter1)
  + motivation
  + datasets
  + related work
  + research questions
2. [**Methods**](#chapter2)
  + which methods
  + why
3. [**Results**](#chapter3)
  + presentation of results
4. [**Discussion and conclusion**](#chapter4)
  + do assumptions hold
  + strengths and weaknesses
5. [**References**](#chapter5)

## 1. Introduction{#chapter1}

Nowadays, global warming is taken as an undeniable truth, being confirmed by multiple studies across the globe. Rising temperatures can have negative effects on likelihod of different populations around the world, mainly by affecting conditions for growing foods, disturbing sensitive ecosystems, and rising sea levels. Croatia is consisted of three distinctive parts; continental part, mountainous part and coastal part. Each one of them has different climate and temperatures even though whole country is classified as having continental climate and coast hosting mediterannean climate. We would like to have a sense of how climate change and increasing temperatures affect different parts of Croatia, which can be used as a strarting point for more detailed research in order to plan mitigation measures for possible negative effects of increasing temperatures.
With wide availability of sensors which measure atmospheric conditions, we can access data for desired area and inquire on how temperatures affect that area.
In this work, we will look at temperature data recorded on 30 stations on the territory of Republic of Croatia, starting in 2004. and ending in 2020. Data is provided by NOAA (National Oceanic and Atmospheric Administration)[[1]](#source1). Inspiration was taken from two papers, Spatio-temporal regression kriging model of mean daily temperature for Croatia by Sekulić et al. [[2]](#source2) and Spatio-temporal prediction of daily temperatures using time-series of MODIS LST images by Hengl et al. [[3]](#source3). Other work which was used as and aid in writing code and structuring data processing was vignettes for **gstat** and **spacetime** [[5]](#source5)[[6]](#source6)[[7]](#source7), as well as tutorial on spatio-temporal krigging [[4]](#source4)

In this work, we want to answer the following questions:
  * Is there a trend of rising temperature in Croatia?
  * If there is, which areas are affected by this and how?
  * By looking at the results of krigging, can we notice any factors which may influence temperature on the territory of Croatia, for example altitude, latitude, proximity to sea or anything else, which could be used for another study (kriging with multiple variables)?

## 2. Methods{#chapter2}
Method I'm going to use is ordinary spatio-temporal kriging. ----Don't know why this is best yet---
In order to be able to perform kriging, I need to model a spatio-temporal variogram. In usual case of purely spatial kriging, matrix of covariances is consisted only of spatial distances between stations. In my case, temporal distance has to be taken into account as well. Workflow will have the following order:
1. Download data
2. Process data (I selected only stations and years which have complete data)
3. Create STFDF object which holds station coordinates, yearly average temperature readings for these stations and their timestamps

From this data we will then be able to model:
4. Sample spatio-temporal variogram (for all years and all stations)
5. Find the best fitting model for sample variogram
6. Create spatio-temporal prediction grid to be used for kriging
7. Perform kriging

Main packages I will be using are **gstat** package which provides functions for geostatistical analysis (creating sample and model variogram, and fitting latter to the former), and **spacetime** package (used for creating structured spatio-temporal data which serves as input for modelling variograms and later performing kriging).

## 3. Results{#chapter3}

This chapter will present results.

```{r Load all packages, echo=TRUE, message=FALSE}
library(plyr)
library(tidyverse)
library(sf)
library(ggplot2)
library(stars)
library(gstat)
library(lubridate)
library(spacetime)
library(sp)
library(stringr)
library(maps)
library(rnaturalearth)
library(ggrepel)
library(RColorBrewer)
library(xts)
library(maptools)
```

Import stations
```{r Import stations, echo=TRUE, message=FALSE}
stations <- read_csv("stations2.csv")
```

Round all dates down to year
```{r Round all dates, echo=TRUE, message=FALSE}
stations$YEAR <- floor_date(stations$DATE, "year")
```

Temperature is in Fahrenheit so let's convert it to Celsius degrees
```{r Temperature conversion, echo=TRUE, message=FALSE}
stations$TEMP <- (((stations$TEMP)-32)/1.8)
```

We need to aggregate data so we get annual mean (from daily means), so we will have annual daily mean for every station for all years.
```{r Aggregate by year, echo=TRUE, message=FALSE}
agg = aggregate(stations$TEMP,list(YEAR = stations$YEAR,STATION_ID = stations$STATION,NAME = stations$NAME,LAT = stations$LATITUDE,LONG = stations$LONGITUDE,ELEVATION = stations$ELEVATION), mean)
colnames(agg)[which(names(agg) == "x")] <- "MEAN_TEMP"
agg <- agg[order(agg$YEAR), ]
agg$YEAR <- format(as.Date(agg$YEAR, format="%d/%m/%Y"),"%Y")
agg$STATION_ID <- substring(agg$STATION_ID,1,5)
```

There are 32 possible stations:
```{r Show stations, echo=TRUE}
print(unique(agg$NAME))
```

Now we have issue because it seems that not every year has data for every station.
We can check that in the following way:
```{r Check for missing data, echo=TRUE}
checker <- function(input_file) {
counter <- 0
full_counter <- 0
stations <- c()
my_list <- c()
differences <- c()
for (unique_year in unique(input_file$YEAR)) {
  for (year in input_file$YEAR) {
    if (unique_year == year) {
      counter = counter + 1
      full_counter = full_counter + 1
      stations[length(stations)+1] <- input_file$STATION_ID[full_counter]
    }
  }
  difference <- setdiff(unique(input_file$STATION_ID),stations)
  differences[(length(differences)+1)] <- paste(unlist(difference),collapse=",")
  my_list[(length(my_list)+1)] <- counter
  counter <- 0
  stations <- c()
}
n_stations_by_year <- data.frame(YEAR = unique(input_file$YEAR),N_stations = my_list, DIFFERENCE_ID = differences)
return(n_stations_by_year)
}
checker(agg)
```

To make things coherent (I'm not sure if this is correct way) we will remove records for year 2005. and also all records for stations 14442 and 14446.
Let's include only data we need:
```{r Clean data, echo=TRUE, message=FALSE}
agg4 <- subset(agg, YEAR != "2005" & STATION_ID != "14442" & STATION_ID != "14446")
```
Now we should have dataset without year 2005(some stations missing data), and without stations 14442 and 14446. Let's check if that's correct:
```{r Check data again, echo=TRUE}
checker(agg4)
```
As we can see, now all years have same stations (30 of them). Next thing we can do is create space-time object STFDF and map of stations we use.

Let's see where are stations located:
Load data for Croatian map
```{r Load data for map, echo=TRUE, message=FALSE}
croatia_sea <- st_read("HRV_adm/croatia.geojson")
croatia_land <- st_read("HRV_adm/croatia_land.geojson")
single_sf <- bind_rows(list(croatia_sea,croatia_land))
```

Create map for Croatia together with stations.
```{r Croatia map, fig.align='center',fig.width=10, fig.height=7, include=TRUE, results='hide'}
stations_only <- data.frame(LON = agg4$LONG[1:30], LAT = agg4$LAT[1:30])
NAME <- c(agg4$NAME[1:30])
stations_only <- cbind(stations_only,NAME)
plot_with_points <- ggplot() +
  geom_sf(data = single_sf) +
  geom_point(data = stations_only,
             mapping = aes(x = LON, y = LAT),
             colour = "red",
             size = 2,
             shape = 4) +
  coord_sf()

plot_with_points + 
  geom_label_repel(data = stations_only, aes(x = LON, y = LAT,label = NAME),
                  box.padding   = 0.1, 
                  point.padding = 0.5,
                  size = 2,
                  segment.color = 'grey50') +
  theme_classic()
```


Create space-time object STFDF
```{r Create STFDF object, echo=TRUE, message=FALSE, warning=FALSE}
# Get station names and coordinates(LON-LAT in WGS84)
station_coords_df <- cbind(LON = agg4$LONG[1:30], LAT = agg4$LAT[1:30])
row.names(station_coords_df) <- paste(agg4$NAME[1:30])
station_coords <- SpatialPoints(station_coords_df,CRS("+init=epsg:4326"))

# Transform coordinates to projection for Croatia
station_coords <- spTransform(station_coords, CRS("+init=epsg:3765"))
# Check for duplicates. If we have duplicates, kriging won't work because we get singular covariance matrices
zerodist(station_coords)

# Time stamps
time <- as.POSIXct(unique(agg4$YEAR),tz="", "%Y")

# Temperature values
values <- agg4$MEAN_TEMP

# Create STFDF object (for static spatial instances)
df <- data.frame(values = values)
st_object <- STFDF(station_coords,time,data=df)
```

Plot STFDF data
```{r Plot STFF data, echo=TRUE, fig.align="center"}
# Pull map of Croatia
map.cro = map2SpatialLines(map("world", "croatia", fill=TRUE, ol="transparent", plot=F))
proj4string(map.cro) = "+init=epsg:4326"
map.cro = spTransform(map.cro, "+init=epsg:3765")

# Plot multi-panel plots, one panel for every year showing locations in the country with colors for average temperature
layout = list(list("sp.lines", map.cro, col='grey'),list("sp.points", station_coords, first=F, cex=.5))
stplot(st_object, sp.layout = layout, main="Temperature values",cuts=11,col.regions=rev(brewer.pal(11, "RdBu")))


# Time series of temperature for every station
stplot(st_object, mode="tp", main="Temperature by station",ylab="Average emperature",xlab="Year")

# Time series of temperature for all stations
stplot(st_object, mode="ts",main="Temperature by station",xlab="Year",ylab="Average temperature")

# Plot space-time plots
scales=list(x=list(rot = 45))
stplot(st_object, mode = "xt", cuts=11,scales = scales,main="Average temperature", ylab="Year", xlab = NULL,col.regions=rev(brewer.pal(11, "RdBu")))
```
From the above plots we can clearly see trend of rising average temperatures, as well as differences between stations. This makes sense because latitude affects this, as well as station's altitude (for example, ZAVIZAN is highest and coldest station).
Now I will do analysis per season. Due to availability of the data, this data will be for years 2007.-2020.
```{r Aggregate by month, echo=TRUE, message=FALSE,fig.align="center"}
# Aggregate data by year and month
stations$year <- strftime(stations$DATE, "%Y")  
stations$month <- strftime(stations$DATE, "%m")
year.month <- aggregate(TEMP ~ month + year + STATION + NAME,stations,FUN = mean)

# Again like before, I will completely remove year 2005 and stations 14442 and 14446,as well as 2004 since we can't take seasons from 2004 if we don't have data from 2005.
year.month.cleaned <- subset(year.month, year != "2004" & year != "2005" & STATION != "14442099999" & STATION != "14446099999")

# I also need to remove December for year 2020 because that data would be used for Winter 2020/2021 and I don't have data for 2021, as well as January-November for 2006. since December for 2006. will be dedicated to Winter of 2007.
year.month.final <- year.month.cleaned[!(year.month.cleaned$year %in% "2020" & year.month.cleaned$month %in% c("12")),]

year.month.final <- year.month.final[!(year.month.final$year %in% "2006" & year.month.final$month %in% c("01","02","03","04","05","06","07","08","09","10","11")),]

# Now I can pull out individual seasons
# Winter starts in December 2006 because we don't have data for 2005
# Then following Spring, Summer and Autumn start are taken from 2007
winter <- year.month.final[year.month.final$month %in% c("12","01","02"),]
spring <- year.month.final[year.month.final$month %in% c("03","04","05"),]
summer <- year.month.final[year.month.final$month %in% c("06","07","08"),]
autumn <- year.month.final[year.month.final$month %in% c("09","10","11"),]


# Next I need average temperature of all three months which compromise one season
# For that reason I made small function which will do this for every season

season.averager <- function(df) {
  
season.average <- data.frame(matrix(ncol=3,nrow=0))
colnames(season.average) <- c("AVERAGE","STATION","YEAR")
i = 0
sum = 0
for (row in 1:nrow(df)) {
  sum = (sum + df$TEMP[row])
  i = i + 1
  if (i == 3) {
    season.average[nrow(season.average)+1,] <- c(sum/3,df$NAME[row],df$year[row])
    sum = 0
    i = 0
  }
}
return(season.average[order(season.average$YEAR),])
}

# Calculate averages for every season
winter.averaged <- season.averager(winter)
spring.averaged <- season.averager(spring)
summer.averaged <- season.averager(summer)
autumn.averaged <- season.averager(autumn)

# Now I will again created STFDF object so I can create nice time series

# Time stamps
season.time <- as.POSIXct("2000-12-31", tz = "")+365*24*3600*(7:20)

# Winter
st.winter <- STFDF(station_coords,season.time,data=data.frame(as.numeric(winter.averaged$AVERAGE)))
stplot(st.winter,main="Winter",mode = "xt", cuts=11,scales = scales, ylab="Year", xlab = NULL,col.regions=rev(brewer.pal(11, "RdBu")))
stplot(st.winter,main="Winter",ylab="Temperature",xlab="Year", mode="tp")
stplot(st.winter,main="Winter",ylab="Temperature",xlab="Year", mode="ts")

# Spring
st.spring <- STFDF(station_coords,season.time,data=data.frame(as.numeric(spring.averaged$AVERAGE)))
stplot(st.spring,main="Spring", mode = "xt", cuts=11,scales = scales, ylab="Year", xlab = NULL,col.regions=rev(brewer.pal(11, "RdBu")))
stplot(st.spring,main="Spring",ylab="Temperature",xlab="Year", mode="tp")
stplot(st.spring,main="Spring",ylab="Temperature",xlab="Year", mode="ts")

# Summer
st.summer <- STFDF(station_coords,season.time,data=data.frame(as.numeric(summer.averaged$AVERAGE)))
stplot(st.summer,main="Summer", mode = "xt", cuts=11,scales = scales, ylab="Year", xlab = NULL,col.regions=rev(brewer.pal(11, "RdBu")))
stplot(st.summer,main="Summer",ylab="Temperature",xlab="Year", mode="tp")
stplot(st.summer,main="Summer",ylab="Temperature",xlab="Year", mode="ts")

# Autumn
st.autumn <- STFDF(station_coords,season.time,data=data.frame(as.numeric(autumn.averaged$AVERAGE)))
stplot(st.autumn,main="Autumn", mode = "xt", cuts=11,scales = scales, ylab="Year", xlab = NULL,col.regions=rev(brewer.pal(11, "RdBu")))
stplot(st.autumn, main="Autumn",ylab="Temperature",xlab="Year",mode="tp")
stplot(st.autumn, main="Autumn",ylab="Temperature",xlab="Year",mode="ts")
```
Here I averaged readings for all seasons as well as for full year(without taking seasons into account), so correlation will be calculated with years on x-axis and average temperature from all stations for a given season (or for full year).
```{r Correlation coefficients, echo=TRUE, message=FALSE}
# Whole year (all 12 months taken into average)
year.mean <- aggregate(agg4$MEAN_TEMP, list(as.numeric(agg4$YEAR)), mean)
print(paste("Change in average temperature from year ",year.mean[1,1]," to year ", year.mean[16,1]," is",(year.mean[16,2]-year.mean[1,2])))
year.mean.lm <- lm(Group.1 ~ x, data = year.mean)
summary(year.mean.lm)

cor.test(x=as.numeric(year.mean$Group.1),y=year.mean$x,method = "pearson")

# Winter 
winter.mean <- aggregate(as.numeric(winter.averaged$AVERAGE), list(winter.averaged$YEAR), mean)
print(paste("Change in average temperature from year ",winter.mean[1,1]," to year ", winter.mean[14,1]," is",(year.mean[14,2]-year.mean[1,2])))
cor.test(x=as.numeric(winter.mean$Group.1),y=winter.mean$x,method = "pearson")

# Spring
spring.mean <- aggregate(as.numeric(spring.averaged$AVERAGE), list(spring.averaged$YEAR), mean)
print(paste("Change in average temperature from year ",spring.mean[1,1]," to year ", spring.mean[14,1]," is",(year.mean[14,2]-year.mean[1,2])))
cor.test(x=as.numeric(spring.mean$Group.1),y=spring.mean$x,method = "pearson")

# Summer
summer.mean <- aggregate(as.numeric(summer.averaged$AVERAGE), list(summer.averaged$YEAR), mean)
print(paste("Change in average temperature from year ",summer.mean[1,1]," to year ", summer.mean[14,1]," is",(year.mean[14,2]-year.mean[1,2])))
cor.test(x=as.numeric(summer.mean$Group.1),y=summer.mean$x,method = "pearson")

# Autumn
autumn.mean <- aggregate(as.numeric(autumn.averaged$AVERAGE), list(autumn.averaged$YEAR), mean)
print(paste("Change in average temperature from year ",autumn.mean[1,1]," to year ", autumn.mean[14,1]," is",(year.mean[14,2]-year.mean[1,2])))
cor.test(x=as.numeric(autumn.mean$Group.1),y=autumn.mean$x,method = "pearson")
```
For years, we can see positive correlation wit correlation coefficient 0.72, and with =3.94 and df = 14, p-value is 0.0014 which is significant for confidence interval < 0.05.
For seasons, we can see only significant correlations seems to be for Autumn with correlation coefficient of 0.56 which suggeests increase in temperatures as time goes. With a t=2.3758 and degrees of freedom df=12, p-value is 0.03 which is less than usual significance level of 0.05 so we can say this correlation is significant.
Data suggests that season which has highest increase in temperature is Autumn.


Now we will create sample spatio-temporal variogram using all data from all stations.
```{r Create sample spatio-temporal variogram, echo=TRUE, fig.align="center"}
# Create sample spatio-temporal variogram
sampl.var <- variogramST(values~1,data=st_object)

# Plot 2D plot of variogram
plot(sampl.var, map=F)

# Plot 2D map of variogram
plot(sampl.var, map=T)

# Plot 3D variogram
plot(sampl.var, wireframe=T)
```

Below is a dummy spatial variogram used to fine-tune parameters which will be used later on in fitting of spatio-temporal variogram.
```{r Create sample spatial variogram, echo=TRUE, fig.align="center"}
# Get lag for year 2012
lag8 <- subset(agg4, YEAR == "2012" )

# Set CRS
crs = st_crs("EPSG:3765")

# Create file for use when constructing variogram
lag8.sf = st_as_sf(lag8, coords = c("LONG", "LAT"), crs = "EPSG:4326") %>%
    st_transform(crs)

# Create sample spatial variogram
v = variogram(MEAN_TEMP~1, lag8.sf)

# Save desired parameters (these were achieved experimentally)
lag8_spatial_var_model <- vgm(10, "Exp", 70000)

# Plot variogram
plot(v,lag8_spatial_var_model,plot.numbers=TRUE)
```

Now we create models for spatio-temporal variogram and try to fit them:
```{r Fit variogram, echo=TRUE, message=FALSE, fig.align="center"}
# We have 5 options for fitting; separable, product sum, metric, sum metric, and simple sum metric.
# First thing is to set lower and upper limits for all models
pars.l <- c(sill.s = 0, range.s = 10, nugget.s = 0,sill.t = 0, range.t = 1, nugget.t = 0,sill.st = 0, range.st = 10, nugget.st = 0, anis = 0)
pars.u <- c(sill.s = 10000, range.s = 50000, nugget.s = 100,sill.t = 100000, range.t = 50000, nugget.t = 100,sill.st = 10000, range.st = 50000, nugget.st = 100,anis = 700) 
# ------------------------------------------------------------------------------
# Separable model 
separable <- vgmST("separable", space = vgm(10,"Exp",60000,0),time = vgm(100,"Exp",500,1), sill=1)
separable_fitted <- fit.StVariogram(sampl.var, separable, fit.method=11,method="L-BFGS-B", stAni=1)
print(paste("MSE for Separable model is: ",attr(separable_fitted, "MSE")))
# ------------------------------------------------------------------------------
# Product sum model
prodSumModel <- vgmST("productSum", space = vgm(10,"Exp",60000,0),time = vgm(psill=500,"Exp", range=5000, nugget=0), k=500)
prodSumModel_fitted <- fit.StVariogram(sampl.var, prodSumModel,method = "L-BFGS-B",lower=pars.l)
print(paste("MSE for Product sum model is: ",attr(prodSumModel_fitted, "MSE")))
# ------------------------------------------------------------------------------
# Metric
metric <- vgmST("metric",joint=vgm(10,"Exp",70000,0),stAni=1)
metric_fitted <- fit.StVariogram(sampl.var, metric)
print(paste("MSE for Metric model is: ",attr(metric_fitted, "MSE")))
# ------------------------------------------------------------------------------
# Sum metric
sumMetric <- vgmST("sumMetric", space = vgm(10,"Exp",60000,0),time = vgm(psill=500,"Exp", range=5000, nugget=0), joint = vgm(25,"Exp",60000,0), stAni=500) 
sumMetric_fitted <- fit.StVariogram(sampl.var, sumMetric, method="L-BFGS-B",tunit="hours")
print(paste("MSE for Sum metric model is: ",attr(sumMetric_fitted, "MSE")))
# ------------------------------------------------------------------------------
# Simple sum metric
SimplesumMetric <- vgmST("simpleSumMetric",space = vgm(10,"Exp",60000,0),time = vgm(500,"Exp", 5000, 0), joint = vgm(25,"Exp",60000,0), nugget=1, stAni=500)
SimplesumMetric_fitted <- fit.StVariogram(sampl.var, SimplesumMetric,method = "L-BFGS-B")
print(paste("MSE for Simple sum metric model is: ",attr(SimplesumMetric_fitted, "MSE")))
# ------------------------------------------------------------------------------
# Plot 3D plots for models
plot(sampl.var,list(separable_fitted,prodSumModel_fitted,metric_fitted, sumMetric_fitted, SimplesumMetric_fitted),all=T,wireframe=T)
```
We look at mean square error for every model and see that Sum metric model has lowest value. Even though, as we can see from visual inspection, there is a strange jump in variance at the beginning. For this reason, I choose Metric model which has more gradual rise in variance, similar to example for 2D variogram above where I fine tuned parameters.

Proceed to kriging and display results.
```{r Kriging, echo=TRUE, error=FALSE, warning=FALSE, fig.align="center",fig.width=13}
# Create spatial grid
spatial.grid = SpatialPixels(SpatialPoints(makegrid(map.cro, n = 10000)),
                             proj4string = proj4string(map.cro))

# Create temporal grid
tgrd = seq(min(index(st_object)), max(index(st_object)), length=16)

# Merge two grids into spatio-temporal grid
pred.grd = STF(spatial.grid, tgrd)

# Assign same proj4string due to some issues of two strings not being equal
proj4string(st_object) = proj4string(pred.grd)

# Krige
temp.ST = krigeST(values ~ 1, st_object, pred.grd, metric_fitted)

# Pack borders and stations
layout = list(list("sp.lines", map.cro, col='grey'),list("sp.points", station_coords, first=F, cex=.5))

# Plot all together
stplot(temp.ST,cuts=11,col.regions=rev(brewer.pal(11, "RdBu")), sp.layout = layout)
```

## 4. Discussion and conclusion{#chapter4}

Some discussion here.

## 5. References{#chapter5}

[[1]]{#source1} NOAA https://www.ncei.noaa.gov

[[2]]{#source2} Sekulić, A., Kilibarda, M., Protić, D. et al. Spatio-temporal regression kriging model of mean daily temperature for Croatia. Theor Appl Climatol 140, 101–114 (2020). https://doi.org/10.1007/s00704-019-03077-3

[[3]]{#source3} Hengl, T., Heuvelink, G.B.M., Perčec Tadić, M. et al. Spatio-temporal prediction of daily temperatures using time-series of MODIS LST images. Theor Appl Climatol 107, 265–277 (2012). https://doi.org/10.1007/s00704-011-0464-2

[[4]]{#source4} https://www.r-bloggers.com/2015/08/spatio-temporal-kriging-in-r/

[[5]]{#source5} Pebesma, Edzer.Spacetime: Spatio-Temporal Data in R. Journal of Statistical Software. 51. 1-30. (2012). 10.18637/jss.v051.i07. 

[[6]]{#source6} Pebesma, Edzer, Graeler, Ben. Introduction to spatio-temporal variography  (2021.)

[[7]]{#source7} Pebesma, Edzer, Graeler, Ben. Gerard Heuvelink. Spatio-temporal interpolation using gstat (2016.) 
